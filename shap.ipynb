{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import shap  # SHAP分析\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from catboost import CatBoostRegressor\n",
    "## 为了正确评估模型性能，将数据划分为训练集和测试集，并在训练集上训练模型，在测试集上验证模型性能。\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.sans-serif'] = ['SimHei']  # 或者其他中文字体，确保字体文件存在\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False  # 防止负号显示为方块\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import tqdm\n",
    "import logging\n",
    "import pickle\n",
    "# 设置日志配置，将输出写入文件\n",
    "logging.basicConfig(filename='globa_model_training.log', level=logging.INFO, format='%(asctime)s - %(message)s', filemode='w')\n",
    "\n",
    "def clear_folder(folder_path):\n",
    "    # 确保文件夹存在\n",
    "    if os.path.exists(folder_path):\n",
    "        # 遍历文件夹中的所有文件和子文件夹\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            # 如果是文件，则删除\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "            # 如果是文件夹，则递归删除\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "    else:\n",
    "        print(f\"文件夹 {folder_path} 不存在！\")\n",
    "        # 创建文件夹\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "def standardize_data(x_train, x_test):\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # 对训练数据进行拟合并转换\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    \n",
    "    # 对测试数据进行转换（使用训练数据的均值和标准差进行转换）\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "    \n",
    "    return x_train_scaled, x_test_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '0624'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_predictions(y_true, y_pred, title=None):\n",
    "    years = list(range(1961, 2023))  # 从1961年到2022年\n",
    "\n",
    "    plt.figure(figsize=(12,6))  # 调整图形的大小\n",
    "    # 更改配色：使用深蓝色和橙色，给线条增加标记点\n",
    "    plt.plot(years, y_true, color='#1f77b4', label='True Value', linewidth=2)\n",
    "    plt.plot(years, y_pred, color='#ff7f0e', label='Predicted Value', linewidth=2, linestyle='--')  # 使用虚线\n",
    "    plt.legend(loc='best', fontsize=12)  # 增加图例字体大小\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title, fontsize=16, fontweight='bold')  # 设置标题的字体大小和粗体\n",
    "    plt.xlabel('Year', fontsize=14)\n",
    "    plt.ylabel('Ammonia Emission', fontsize=14)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)  # 添加网格线，增加可读性\n",
    "    plt.tight_layout()  # 自动调整子图参数，使图形更紧凑\n",
    "\n",
    "    # 保存图像而不是显示图像\n",
    "    plt.savefig(f'../0311_pred_result/{title}.png', dpi=300)  # 保存为 PNG 格式，分辨率为300\n",
    "    plt.close()\n",
    "\n",
    "# 评估模型性能\n",
    "def evaluate_model(model, x_train_scaled, y_train, x_test_scaled, y_test):\n",
    "    \n",
    "    if isinstance(model, CatBoostRegressor):\n",
    "        model.fit(x_train_scaled, y_train, eval_set=(x_test_scaled, y_test), use_best_model=True)\n",
    "    else:\n",
    "        model.fit(x_train_scaled, y_train)\n",
    "    y_pred_train = model.predict(x_train_scaled)\n",
    "    y_pred_test = model.predict(x_test_scaled)\n",
    "    \n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    # print(f\"Train R²: {train_r2:.4f}\")\n",
    "    # print(f\"Test R²: {test_r2:.4f}\")\n",
    "    return train_r2 , test_r2\n",
    "\n",
    "# SHAP分析\n",
    "def shap_analysis(model, X, name=None, country=None):\n",
    "    # 判断模型类型，选择相应的解释器\n",
    "    if isinstance(model, LinearRegression):\n",
    "        explainer = shap.LinearExplainer(model, X)\n",
    "    elif isinstance(model, (SVR, GaussianProcessRegressor)):\n",
    "        explainer = shap.KernelExplainer(model.predict, X)\n",
    "    elif isinstance(model, RandomForestRegressor) or isinstance(model, xgb.XGBRegressor):\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "    elif isinstance(model, CatBoostRegressor):\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {type(model)}\")\n",
    "\n",
    "    # 计算SHAP值\n",
    "    shap_values = explainer.shap_values(X)\n",
    "\n",
    "    # 可视化SHAP值\n",
    "    shap.summary_plot(shap_values, X, plot_type=\"dot\", show=False)\n",
    "    \n",
    "    # 保存shap图\n",
    "    if country is not None:\n",
    "        plt.savefig(f'../{date}_shap_result/{country}_{name}_shap_summary_plot.png')\n",
    "    else:\n",
    "        plt.savefig(f'../{date}_shap_result/{name}_shap_summary_plot.png')\n",
    "    \n",
    "    # 关闭图形，避免后续图形显示问题\n",
    "    plt.close()\n",
    "\n",
    "    # 计算每个特征的平均绝对SHAP值\n",
    "    feature_importance = pd.DataFrame()\n",
    "    feature_importance['特征'] = X.columns\n",
    "    \n",
    "    # 如果shap_values是一维数组（对于回归问题）\n",
    "    if isinstance(shap_values, np.ndarray) and len(shap_values.shape) == 2:\n",
    "        # 计算每个特征的平均绝对SHAP值\n",
    "        feature_importance['平均绝对SHAP值'] = np.abs(shap_values).mean(axis=0)\n",
    "        # 计算每个特征的平均SHAP值（可能为正或负）\n",
    "        feature_importance['平均SHAP值'] = shap_values.mean(axis=0)\n",
    "        feature_importance['归一化平均绝对SHAP值'] = feature_importance['平均绝对SHAP值'] / np.sum(feature_importance['平均绝对SHAP值'])\n",
    "    \n",
    "    # 按重要性排序\n",
    "    feature_importance = feature_importance.sort_values('归一化平均绝对SHAP值', ascending=False)\n",
    "    \n",
    "    # 保存特征重要性到CSV文件\n",
    "    output_dir = f'../{date}_shap_result'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # 保存详细的SHAP值（每个样本的每个特征的SHAP值）\n",
    "    detailed_shap_values = pd.DataFrame(shap_values, columns=X.columns)\n",
    "    detailed_shap_values.to_csv(f'{output_dir}/{country}_{name}_detailed_shap_values.csv', index=False)\n",
    "    \n",
    "    # 保存特征重要性摘要\n",
    "    feature_importance.to_csv(f'{output_dir}/{country}_{name}_feature_importance.csv', index=False)\n",
    "    \n",
    "    # 打印特征重要性\n",
    "    print(f\"\\n特征重要性排名 (模型: {name}, 国家: {country}):\")\n",
    "    print(feature_importance)\n",
    "\n",
    "# 模型选择\n",
    "models = {\n",
    "    'SVR': SVR(\n",
    "        kernel='rbf',\n",
    "        degree=3,\n",
    "        tol=0.001\n",
    "    ),\n",
    "    'XGBoost': xgb.XGBRegressor(\n",
    "        max_depth=3,               # 降低树的深度\n",
    "        learning_rate=0.05,        # 降低学习率\n",
    "        n_estimators=500,          # 增加迭代次数来弥补学习率降低的效果\n",
    "        n_jobs=4,\n",
    "        colsample_bytree=0.6,      # 调整特征采样比例\n",
    "        subsample=0.7,             # 调整训练样本的采样比例\n",
    "        min_child_weight=3,        # 增加每个叶子节点的最小权重\n",
    "        alpha=1,                   # 增加L1正则化\n",
    "        random_state=32\n",
    "    ),  \n",
    "    'LR': LinearRegression(\n",
    "        fit_intercept=True,\n",
    "        n_jobs=1\n",
    "    ),\n",
    "    # 'GPR': GaussianProcessRegressor(\n",
    "    #     kernel=RBF(length_scale=1.0)\n",
    "    # ),\n",
    "    'RandomForest': RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        criterion='squared_error',\n",
    "        max_depth=15,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        min_weight_fraction_leaf=0.0,\n",
    "        max_features=5,\n",
    "        max_leaf_nodes=None,\n",
    "        bootstrap=True,\n",
    "        oob_score=False,\n",
    "        n_jobs=1,\n",
    "        random_state=None,\n",
    "        verbose=0,\n",
    "        warm_start=False\n",
    "    ),\n",
    "    'svr': SVR(\n",
    "        kernel='rbf',\n",
    "        degree=3,\n",
    "        coef0=0.0,\n",
    "        tol=0.001,\n",
    "        C=1.0,\n",
    "        epsilon=0.1,\n",
    "        shrinking=True,\n",
    "        cache_size=200,\n",
    "        verbose=False,\n",
    "        max_iter=-1\n",
    "    ),\n",
    "    'catboost': CatBoostRegressor(\n",
    "        iterations=1000,\n",
    "        early_stopping_rounds=200,\n",
    "        learning_rate=0.05,\n",
    "        loss_function=\"RMSE\",\n",
    "        eval_metric=\"RMSE\",\n",
    "        depth=6,\n",
    "        min_data_in_leaf=20,\n",
    "        random_seed=42,\n",
    "        logging_level='Silent',\n",
    "        use_best_model=True,\n",
    "        one_hot_max_size=5,\n",
    "        boosting_type=\"Ordered\",\n",
    "        max_ctr_complexity=2,\n",
    "        nan_mode='Min'\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件夹 ../0624_pred_result 不存在！\n",
      "文件夹 ../0624_shap_result 不存在！\n"
     ]
    }
   ],
   "source": [
    "file_path = '国家氨排放强度原因解析_finalprotein.xlsx'\n",
    "file_path_old = '副本国家氨排放强度原因解析V30416.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "df_old = pd.read_excel(file_path_old)\n",
    "# date = '0422'\n",
    "\n",
    "clear_folder(f'../{date}_pred_result')\n",
    "clear_folder(f'../{date}_shap_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>大洲</th>\n",
       "      <th>area</th>\n",
       "      <th>year</th>\n",
       "      <th>areayear</th>\n",
       "      <th>Fertilizer N input intensity</th>\n",
       "      <th>The proportion of BNF in the total N input</th>\n",
       "      <th>Vegetable and fruit land share</th>\n",
       "      <th>Grassland area share</th>\n",
       "      <th>Livestock protein share</th>\n",
       "      <th>The proportion of the number of layer</th>\n",
       "      <th>The proportion of the number of meat cattle</th>\n",
       "      <th>The proportion of the number of meat chicken</th>\n",
       "      <th>The proportion of the number of dairy</th>\n",
       "      <th>The proportion of the number of sheep</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Livestock NUE</th>\n",
       "      <th>Crop NUE</th>\n",
       "      <th>The proportion of manure fertilizer</th>\n",
       "      <th>Ammonia intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1961</td>\n",
       "      <td>Afghanistan1961</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.069490</td>\n",
       "      <td>0.047887</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.090492</td>\n",
       "      <td>0.017874</td>\n",
       "      <td>0.034472</td>\n",
       "      <td>0.015640</td>\n",
       "      <td>0.223428</td>\n",
       "      <td>0.708586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016217</td>\n",
       "      <td>0.687050</td>\n",
       "      <td>28.122601</td>\n",
       "      <td>0.130973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1962</td>\n",
       "      <td>Afghanistan1962</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.068705</td>\n",
       "      <td>0.046264</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.091496</td>\n",
       "      <td>0.019537</td>\n",
       "      <td>0.036536</td>\n",
       "      <td>0.016651</td>\n",
       "      <td>0.222009</td>\n",
       "      <td>0.705267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016645</td>\n",
       "      <td>0.680001</td>\n",
       "      <td>28.523233</td>\n",
       "      <td>0.133775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1963</td>\n",
       "      <td>Afghanistan1963</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.067865</td>\n",
       "      <td>0.045832</td>\n",
       "      <td>0.792602</td>\n",
       "      <td>0.106468</td>\n",
       "      <td>0.019833</td>\n",
       "      <td>0.036586</td>\n",
       "      <td>0.016599</td>\n",
       "      <td>0.240214</td>\n",
       "      <td>0.686767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017499</td>\n",
       "      <td>0.692667</td>\n",
       "      <td>29.297122</td>\n",
       "      <td>0.150929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1964</td>\n",
       "      <td>Afghanistan1964</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.069574</td>\n",
       "      <td>0.048010</td>\n",
       "      <td>0.791452</td>\n",
       "      <td>0.100537</td>\n",
       "      <td>0.020527</td>\n",
       "      <td>0.036838</td>\n",
       "      <td>0.017106</td>\n",
       "      <td>0.238255</td>\n",
       "      <td>0.687275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017755</td>\n",
       "      <td>0.727601</td>\n",
       "      <td>54.369007</td>\n",
       "      <td>0.136914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1965</td>\n",
       "      <td>Afghanistan1965</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.068764</td>\n",
       "      <td>0.051077</td>\n",
       "      <td>0.791348</td>\n",
       "      <td>0.104590</td>\n",
       "      <td>0.021382</td>\n",
       "      <td>0.035950</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.255529</td>\n",
       "      <td>0.669663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018486</td>\n",
       "      <td>0.723083</td>\n",
       "      <td>56.018675</td>\n",
       "      <td>0.137684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10783</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2018</td>\n",
       "      <td>Zimbabwe2018</td>\n",
       "      <td>0.013453</td>\n",
       "      <td>0.260781</td>\n",
       "      <td>0.034954</td>\n",
       "      <td>0.810788</td>\n",
       "      <td>0.332854</td>\n",
       "      <td>0.031714</td>\n",
       "      <td>0.278691</td>\n",
       "      <td>0.127887</td>\n",
       "      <td>0.343577</td>\n",
       "      <td>0.193321</td>\n",
       "      <td>1464.904683</td>\n",
       "      <td>0.057702</td>\n",
       "      <td>0.529415</td>\n",
       "      <td>0.164170</td>\n",
       "      <td>0.229982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10784</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2019</td>\n",
       "      <td>Zimbabwe2019</td>\n",
       "      <td>0.012224</td>\n",
       "      <td>0.229063</td>\n",
       "      <td>0.048898</td>\n",
       "      <td>0.820466</td>\n",
       "      <td>0.437195</td>\n",
       "      <td>0.029455</td>\n",
       "      <td>0.245166</td>\n",
       "      <td>0.174000</td>\n",
       "      <td>0.321075</td>\n",
       "      <td>0.211223</td>\n",
       "      <td>1348.452786</td>\n",
       "      <td>0.062559</td>\n",
       "      <td>0.396521</td>\n",
       "      <td>0.175184</td>\n",
       "      <td>0.267709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10785</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2020</td>\n",
       "      <td>Zimbabwe2020</td>\n",
       "      <td>0.012660</td>\n",
       "      <td>0.233394</td>\n",
       "      <td>0.055069</td>\n",
       "      <td>0.815258</td>\n",
       "      <td>0.336330</td>\n",
       "      <td>0.034020</td>\n",
       "      <td>0.235557</td>\n",
       "      <td>0.170546</td>\n",
       "      <td>0.322363</td>\n",
       "      <td>0.209912</td>\n",
       "      <td>1251.309431</td>\n",
       "      <td>0.059986</td>\n",
       "      <td>0.544224</td>\n",
       "      <td>0.181769</td>\n",
       "      <td>0.220883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10786</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2021</td>\n",
       "      <td>Zimbabwe2021</td>\n",
       "      <td>0.016138</td>\n",
       "      <td>0.229331</td>\n",
       "      <td>0.047907</td>\n",
       "      <td>0.822878</td>\n",
       "      <td>0.326809</td>\n",
       "      <td>0.028785</td>\n",
       "      <td>0.245962</td>\n",
       "      <td>0.184607</td>\n",
       "      <td>0.313952</td>\n",
       "      <td>0.200147</td>\n",
       "      <td>1303.207454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.147741</td>\n",
       "      <td>0.196094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10787</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2022</td>\n",
       "      <td>Zimbabwe2022</td>\n",
       "      <td>0.011677</td>\n",
       "      <td>0.269578</td>\n",
       "      <td>0.039362</td>\n",
       "      <td>0.820724</td>\n",
       "      <td>0.364788</td>\n",
       "      <td>0.028933</td>\n",
       "      <td>0.255078</td>\n",
       "      <td>0.155216</td>\n",
       "      <td>0.316321</td>\n",
       "      <td>0.209870</td>\n",
       "      <td>1321.793547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.199629</td>\n",
       "      <td>0.204456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10788 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           大洲         area  year         areayear  \\\n",
       "0        Asia  Afghanistan  1961  Afghanistan1961   \n",
       "1        Asia  Afghanistan  1962  Afghanistan1962   \n",
       "2        Asia  Afghanistan  1963  Afghanistan1963   \n",
       "3        Asia  Afghanistan  1964  Afghanistan1964   \n",
       "4        Asia  Afghanistan  1965  Afghanistan1965   \n",
       "...       ...          ...   ...              ...   \n",
       "10783  Africa     Zimbabwe  2018     Zimbabwe2018   \n",
       "10784  Africa     Zimbabwe  2019     Zimbabwe2019   \n",
       "10785  Africa     Zimbabwe  2020     Zimbabwe2020   \n",
       "10786  Africa     Zimbabwe  2021     Zimbabwe2021   \n",
       "10787  Africa     Zimbabwe  2022     Zimbabwe2022   \n",
       "\n",
       "       Fertilizer N input intensity  \\\n",
       "0                          0.000131   \n",
       "1                          0.000130   \n",
       "2                          0.000129   \n",
       "3                          0.000071   \n",
       "4                          0.000071   \n",
       "...                             ...   \n",
       "10783                      0.013453   \n",
       "10784                      0.012224   \n",
       "10785                      0.012660   \n",
       "10786                      0.016138   \n",
       "10787                      0.011677   \n",
       "\n",
       "       The proportion of BNF in the total N input  \\\n",
       "0                                        0.069490   \n",
       "1                                        0.068705   \n",
       "2                                        0.067865   \n",
       "3                                        0.069574   \n",
       "4                                        0.068764   \n",
       "...                                           ...   \n",
       "10783                                    0.260781   \n",
       "10784                                    0.229063   \n",
       "10785                                    0.233394   \n",
       "10786                                    0.229331   \n",
       "10787                                    0.269578   \n",
       "\n",
       "       Vegetable and fruit land share  Grassland area share  \\\n",
       "0                            0.047887              0.794702   \n",
       "1                            0.046264              0.793651   \n",
       "2                            0.045832              0.792602   \n",
       "3                            0.048010              0.791452   \n",
       "4                            0.051077              0.791348   \n",
       "...                               ...                   ...   \n",
       "10783                        0.034954              0.810788   \n",
       "10784                        0.048898              0.820466   \n",
       "10785                        0.055069              0.815258   \n",
       "10786                        0.047907              0.822878   \n",
       "10787                        0.039362              0.820724   \n",
       "\n",
       "       Livestock protein share  The proportion of the number of layer  \\\n",
       "0                     0.090492                               0.017874   \n",
       "1                     0.091496                               0.019537   \n",
       "2                     0.106468                               0.019833   \n",
       "3                     0.100537                               0.020527   \n",
       "4                     0.104590                               0.021382   \n",
       "...                        ...                                    ...   \n",
       "10783                 0.332854                               0.031714   \n",
       "10784                 0.437195                               0.029455   \n",
       "10785                 0.336330                               0.034020   \n",
       "10786                 0.326809                               0.028785   \n",
       "10787                 0.364788                               0.028933   \n",
       "\n",
       "       The proportion of the number of meat cattle  \\\n",
       "0                                         0.034472   \n",
       "1                                         0.036536   \n",
       "2                                         0.036586   \n",
       "3                                         0.036838   \n",
       "4                                         0.035950   \n",
       "...                                            ...   \n",
       "10783                                     0.278691   \n",
       "10784                                     0.245166   \n",
       "10785                                     0.235557   \n",
       "10786                                     0.245962   \n",
       "10787                                     0.255078   \n",
       "\n",
       "       The proportion of the number of meat chicken  \\\n",
       "0                                          0.015640   \n",
       "1                                          0.016651   \n",
       "2                                          0.016599   \n",
       "3                                          0.017106   \n",
       "4                                          0.017476   \n",
       "...                                             ...   \n",
       "10783                                      0.127887   \n",
       "10784                                      0.174000   \n",
       "10785                                      0.170546   \n",
       "10786                                      0.184607   \n",
       "10787                                      0.155216   \n",
       "\n",
       "       The proportion of the number of dairy  \\\n",
       "0                                   0.223428   \n",
       "1                                   0.222009   \n",
       "2                                   0.240214   \n",
       "3                                   0.238255   \n",
       "4                                   0.255529   \n",
       "...                                      ...   \n",
       "10783                               0.343577   \n",
       "10784                               0.321075   \n",
       "10785                               0.322363   \n",
       "10786                               0.313952   \n",
       "10787                               0.316321   \n",
       "\n",
       "       The proportion of the number of sheep          GDP  Livestock NUE  \\\n",
       "0                                   0.708586          NaN       0.016217   \n",
       "1                                   0.705267          NaN       0.016645   \n",
       "2                                   0.686767          NaN       0.017499   \n",
       "3                                   0.687275          NaN       0.017755   \n",
       "4                                   0.669663          NaN       0.018486   \n",
       "...                                      ...          ...            ...   \n",
       "10783                               0.193321  1464.904683       0.057702   \n",
       "10784                               0.211223  1348.452786       0.062559   \n",
       "10785                               0.209912  1251.309431       0.059986   \n",
       "10786                               0.200147  1303.207454            NaN   \n",
       "10787                               0.209870  1321.793547            NaN   \n",
       "\n",
       "       Crop NUE  The proportion of manure fertilizer  Ammonia intensity  \n",
       "0      0.687050                            28.122601           0.130973  \n",
       "1      0.680001                            28.523233           0.133775  \n",
       "2      0.692667                            29.297122           0.150929  \n",
       "3      0.727601                            54.369007           0.136914  \n",
       "4      0.723083                            56.018675           0.137684  \n",
       "...         ...                                  ...                ...  \n",
       "10783  0.529415                             0.164170           0.229982  \n",
       "10784  0.396521                             0.175184           0.267709  \n",
       "10785  0.544224                             0.181769           0.220883  \n",
       "10786       NaN                             0.147741           0.196094  \n",
       "10787       NaN                             0.199629           0.204456  \n",
       "\n",
       "[10788 rows x 19 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_old.columns\n",
    "quadrant_cols = df['区分象限']\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[10445]\n",
    "# 删除df.iloc[10445]和5237          \n",
    "df = df.drop(df.index[10445])\n",
    "df = df.drop(df.index[5237])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据补全"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_missing_by_area(df, area_col='area', year_col='year', value_col='value', model='SVR'):\n",
    "    \"\"\"\n",
    "    对每个area分组，使用线性回归模型插值每个国家的前几年空值。\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): 输入数据，包含area, country, year, value列\n",
    "    area_col (str): 区域列名\n",
    "    country_col (str): 国家列名\n",
    "    year_col (str): 年份列名\n",
    "    value_col (str): 需要插值的数值列名\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: 插值后的数据框\n",
    "    \"\"\"\n",
    "    # 复制数据框以避免修改原始数据\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # 获取所有唯一区域\n",
    "    areas = result_df[area_col].unique()\n",
    "    \n",
    "    for area in areas:\n",
    "        # 提取当前区域的数据\n",
    "        area_data = result_df[result_df[area_col] == area]\n",
    "        \n",
    "        # 分离非空和空值行\n",
    "        non_null_data = area_data[area_data[value_col].notnull()]\n",
    "        null_data = area_data[area_data[value_col].isnull()]\n",
    "        \n",
    "        # 如果有足够的非空数据进行训练\n",
    "        if len(non_null_data) >= 2:\n",
    "            # 准备训练数据\n",
    "            X_train = non_null_data[year_col].values.reshape(-1, 1)\n",
    "            y_train = non_null_data[value_col].values\n",
    "            \n",
    "            # 数据标准化\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "            if model == 'LinearRegression':\n",
    "                # 训练线性回归模型\n",
    "                model = LinearRegression()\n",
    "                model.fit(X_train, y_train)\n",
    "            elif model == 'SVR':\n",
    "                # 训练非线性回归模型\n",
    "                model = SVR(kernel='rbf', degree=3, tol=0.001)\n",
    "                model.fit(X_train, y_train)\n",
    "            elif model == 'XGBoost':\n",
    "                # 训练XGBoost模型\n",
    "                model = xgb.XGBRegressor(\n",
    "                    max_depth=3,\n",
    "                    learning_rate=0.05,\n",
    "                    n_estimators=500,\n",
    "                    n_jobs=4,\n",
    "                    colsample_bytree=0.6,\n",
    "                    subsample=0.7,\n",
    "                    min_child_weight=3,\n",
    "                    alpha=1,\n",
    "                    random_state=32\n",
    "                )\n",
    "            # 预测空值\n",
    "            if not null_data.empty:\n",
    "                X_pred = null_data[year_col].values.reshape(-1, 1)\n",
    "                # 数据标准化\n",
    "                X_pred = scaler.transform(X_pred)\n",
    "                predicted_values = model.predict(X_pred)\n",
    "                \n",
    "                # 将预测值填回结果数据框\n",
    "                result_df.loc[(result_df[area_col] == area) & \n",
    "                            (result_df[value_col].isnull()), \n",
    "                            value_col] = predicted_values\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大洲                                                 0\n",
      "area                                               0\n",
      "year                                               0\n",
      "areayear                                           0\n",
      "Fertilizer N input intensity                       0\n",
      "The proportion of BNF in the total N input       924\n",
      "Vegetable and fruit land share                     0\n",
      "Grassland area share                               0\n",
      "Livestock protein share                            0\n",
      "The proportion of the number of layer              0\n",
      "The proportion of the number of meat cattle        0\n",
      "The proportion of the number of meat chicken       0\n",
      "The proportion of the number of dairy              0\n",
      "The proportion of the number of sheep              0\n",
      "GDP                                             1566\n",
      "Livestock NUE                                    348\n",
      "Crop NUE                                         348\n",
      "The proportion of manure fertilizer              624\n",
      "Ammonia intensity                                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除Livestock NUE，Crop NUE为0的行\n",
    "df = df[df['Livestock NUE'] != 0]\n",
    "df = df[df['Crop NUE'] != 0]\n",
    "# 删除列名为gdp的列\n",
    "df = df.drop(columns=['GDP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线性插值\n",
    "for column in (df.columns.unique()[df.isnull().sum() > 0]).tolist():\n",
    "    df[column] = df.groupby('area')[column].transform(lambda group: group.interpolate())\n",
    "# 删除year in [2021, 2022]\n",
    "df = df[~df['year'].isin([2021, 2022])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大洲                                                0\n",
      "area                                              0\n",
      "year                                              0\n",
      "areayear                                          0\n",
      "Fertilizer N input intensity                      0\n",
      "The proportion of BNF in the total N input        0\n",
      "Vegetable and fruit land share                    0\n",
      "Grassland area share                              0\n",
      "Livestock protein share                           0\n",
      "The proportion of the number of layer             0\n",
      "The proportion of the number of meat cattle       0\n",
      "The proportion of the number of meat chicken      0\n",
      "The proportion of the number of dairy             0\n",
      "The proportion of the number of sheep             0\n",
      "Livestock NUE                                     0\n",
      "Crop NUE                                          0\n",
      "The proportion of manure fertilizer             487\n",
      "Ammonia intensity                                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = interpolate_missing_by_area(df, value_col=\"GDP\")\n",
    "df = interpolate_missing_by_area(df, value_col=\"The proportion of BNF in the total N input\")\n",
    "# df = interpolate_missing_by_area(df, value_col=\"The proportion of manure fertilizer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Antigua and Barbuda', 'Barbados', 'Dominica', 'Grenada',\n",
       "       'Kiribati', 'Malta', 'Mauritius', 'Saint Lucia', 'Seychelles'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['The proportion of manure fertilizer'].isnull()]['area'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_area = df[df['The proportion of manure fertilizer'].isnull()]['area'].unique() \n",
    "df = df[~df['area'].isin(problem_area)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除Crop NUE 不属于[0, 1]的行\n",
    "df = df[(df['Crop NUE'] >= 0) & (df['Crop NUE'] <= 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countryDataset(df):\n",
    "    # # 去除year in [2021, 2022]\n",
    "    # df = df[~df['year'].isin([2021, 2022])]\n",
    "    # 去空\n",
    "    df.dropna(inplace=True)\n",
    "    # 去除不需要的列\n",
    "    data = df.drop(['大洲', 'area', 'year', 'areayear', 'Ammonia intensity'], axis=1)\n",
    "    # 划分特征和目标变量\n",
    "    X_train = data\n",
    "    y_train = df.loc[:, 'Ammonia intensity']\n",
    "    if X_train.shape[0] == 0:\n",
    "        raise Exception\n",
    "    for area in df['area'].unique():\n",
    "        year = len(df[df['area'] == area]['year'])\n",
    "        step = int(year * 0.8)  \n",
    "        indices = list(range(0, len(X_train), year))  # 以步长为year生成索引\n",
    "        x_tra, x_val, y_tra, y_val = [], [], [], []\n",
    "\n",
    "    # 根据索引分割数据\n",
    "    for start in indices:\n",
    "        end = min(start + step, len(X_train))  # 确保不超出数据长度\n",
    "        x_tra.append(X_train[start:end])\n",
    "        y_tra.append(y_train[start:end])\n",
    "        if end < len(X_train):  # 如果不是最后一段数据，将其后面一部分作为验证集\n",
    "            x_val.append(X_train[end:end + year - step])\n",
    "            y_val.append(y_train[end:end + year - step])\n",
    "\n",
    "    # 合并所有分割的部分\n",
    "    x_tra = pd.concat(x_tra)\n",
    "    y_tra = pd.concat(y_tra)\n",
    "    x_val = pd.concat(x_val)\n",
    "    y_val = pd.concat(y_val)\n",
    "\n",
    "    return X_train, y_train, x_tra, x_val, y_tra, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_plot_model_predictions(y_true, y_pred, title=None):\n",
    "    # 使用数据的索引作为 X 坐标\n",
    "    x_vals = range(len(y_true))  # 使用样本的索引作为 X 坐标\n",
    "\n",
    "    plt.figure(figsize=(12,6))  # 调整图形的大小\n",
    "    # 更改配色：使用深蓝色和橙色，给线条增加标记点\n",
    "    plt.plot(x_vals, y_true, color='#1f77b4', label='True Value', linewidth=2)\n",
    "    plt.plot(x_vals, y_pred, color='#ff7f0e', label='Predicted Value', linewidth=2, linestyle='--')  # 使用虚线\n",
    "    plt.legend(loc='best', fontsize=12)  # 增加图例字体大小\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title, fontsize=16, fontweight='bold')  # 设置标题的字体大小和粗体\n",
    "    plt.xlabel('Index', fontsize=14)  # 改为“Index”或其他你需要的标签\n",
    "    plt.ylabel('Ammonia Emission', fontsize=14)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)  # 添加网格线，增加可读性\n",
    "    plt.tight_layout()  # 自动调整子图参数，使图形更紧凑\n",
    "\n",
    "    # 保存图像而不是显示图像\n",
    "    plt.savefig(f'../{date}_pred_result/{title}.png', dpi=300)  # 保存为 PNG 格式，分辨率为300\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import os\n",
    "from scipy.stats import gaussian_kde\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "# 设置matplotlib中文字体\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'sans-serif']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['axes.labelsize'] = 14  # 增大坐标轴标签\n",
    "plt.rcParams['xtick.labelsize'] = 12  # 增大x轴刻度标签\n",
    "plt.rcParams['ytick.labelsize'] = 12  # 增大y轴刻度标签\n",
    "plt.rcParams['legend.fontsize'] = 12  # 增大图例字体\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "def get_feature_category_colors(feature_names):\n",
    "    \"\"\"分配颜色给不同类别的特征\"\"\"\n",
    "    # 按照要求定义类别\n",
    "    categories = {\n",
    "        'crop': ['Fertilizer N input intensity', 'The proportion of manure fertilizer', \n",
    "                'The proportion of BNF in the total N input', 'Vegetable and fruit land share',\n",
    "                'Crop NUE'],\n",
    "        'Grass': ['Grassland area share'],\n",
    "        'livestock': ['Livestock protein share', 'The proportion of the number of layer', \n",
    "                    'The proportion of the number of meat cattle', 'The proportion of the number of meat chicken',\n",
    "                    'The proportion of the number of dairy', 'The proportion of the number of sheep',\n",
    "                    'Livestock NUE']\n",
    "    }\n",
    "    \n",
    "    category_colors = {\n",
    "        'crop': '#E69F00',      # 金黄\n",
    "        'Grass': '#56B4E9',     # 天蓝\n",
    "        'livestock': '#009E73'  # 青绿\n",
    "    }\n",
    "    \n",
    "    # 为每个特征分配颜色\n",
    "    feature_colors = {}\n",
    "    for feature in feature_names:\n",
    "        for category, features in categories.items():\n",
    "            if feature in features:\n",
    "                feature_colors[feature] = category_colors[category]\n",
    "                break\n",
    "        if feature not in feature_colors:\n",
    "            feature_colors[feature] = '#9E9E9E'  # 默认灰色\n",
    "    \n",
    "    return feature_colors, category_colors, categories\n",
    "\n",
    "def create_combined_shap_plot(shap_values, features, output_path='combined_shap_plot.png'):\n",
    "    \"\"\"\n",
    "    创建组合SHAP图，类似于示例图的布局\n",
    "    \n",
    "    参数:\n",
    "    shap_values: SHAP值数组\n",
    "    features: 特征数据（DataFrame或numpy array）\n",
    "    feature_names: 特征名称列表\n",
    "    output_path: 输出文件路径\n",
    "    \"\"\"\n",
    "    # 如果features是numpy数组，转换为DataFrame\n",
    "    if isinstance(features, np.ndarray):\n",
    "        features = pd.DataFrame(features, columns=feature_names)\n",
    "    else:\n",
    "        feature_names = features.columns\n",
    "    # 计算每个特征的平均绝对SHAP值\n",
    "    mean_abs_shap = np.mean(np.abs(shap_values), axis=0)\n",
    "    \n",
    "    # 创建特征重要性DataFrame并排序\n",
    "    importance_df = pd.DataFrame({\n",
    "        '特征': feature_names,\n",
    "        'SHAP值': mean_abs_shap\n",
    "    })\n",
    "    importance_df = importance_df.sort_values('SHAP值', ascending=True)  # 从小到大排序，绘图时会从下到上显示\n",
    "    \n",
    "    # 获取特征类别和颜色\n",
    "    feature_colors, category_colors, categories = get_feature_category_colors(feature_names)\n",
    "    \n",
    "    # 创建图形：2行2列的不等大子图布局\n",
    "    fig = plt.figure(figsize=(24, 12))\n",
    "    \n",
    "    # 添加子图字母标签\n",
    "    plt.figtext(0.02, 0.98, 'a', fontsize=28, fontweight='bold', color='black', ha='left', va='top')\n",
    "    plt.figtext(0.52, 0.98, 'b', fontsize=28, fontweight='bold', color='black', ha='left', va='top')\n",
    "    plt.figtext(0.77, 0.98, 'c', fontsize=28, fontweight='bold', color='black', ha='left', va='top')\n",
    "    plt.figtext(0.52, 0.48, 'd', fontsize=28, fontweight='bold', color='black', ha='left', va='top')\n",
    "    plt.figtext(0.77, 0.48, 'e', fontsize=28, fontweight='bold', color='black', ha='left', va='top')\n",
    "    \n",
    "    # 子图1: 特征重要性条形图 (a) - 占据左半部分\n",
    "    ax1 = plt.subplot2grid((2, 4), (0, 0), rowspan=2, colspan=2)\n",
    "    \n",
    "    # 按重要性排序的特征（取前15个）\n",
    "    # 如果特征数量不足15个，则全部显示\n",
    "    n_features = min(15, len(importance_df))\n",
    "    top_features = importance_df.tail(n_features)  # 使用tail获取最大的几个值\n",
    "    \n",
    "    # 为每个特征分配颜色\n",
    "    bar_colors = [feature_colors.get(feature, '#B0B0B0') for feature in top_features['特征']]\n",
    "    \n",
    "    # 绘制水平条形图\n",
    "    bars = ax1.barh(range(len(top_features)), \n",
    "                   top_features['SHAP值'],\n",
    "                   color=bar_colors,\n",
    "                   height=0.7)\n",
    "    \n",
    "    # 设置y轴标签\n",
    "    ax1.set_yticks(range(len(top_features)))\n",
    "    ax1.set_yticklabels(top_features['特征'], fontsize=16) \n",
    "\n",
    "    # 设置x轴标签\n",
    "    ax1.set_xlabel('Mean (|SHAP| value)', fontsize=16)   \n",
    "    \n",
    "    # 添加图例\n",
    "    legend_handles = [plt.Rectangle((0,0),1,1, color=color) for color in category_colors.values()]\n",
    "    legend_labels = list(category_colors.keys())\n",
    "    ax1.legend(legend_handles, legend_labels, \n",
    "           loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "           fancybox=True, shadow=False, ncol=4, fontsize=16, frameon=True)\n",
    "    # 设置网格和边框\n",
    "    ax1.grid(axis='x', linestyle='--', alpha=0.3)\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "    \n",
    "    # 从每个类别中选择最重要的特征\n",
    "    top_category_features = []\n",
    "    \n",
    "    # 为每个类别找出最重要的特征\n",
    "    for category, features_list in categories.items():\n",
    "        # 过滤出当前类别的特征\n",
    "        category_features = importance_df[importance_df['特征'].isin(features_list)]\n",
    "        if not category_features.empty:\n",
    "            if category == 'livestock':\n",
    "                # 对于livestock类别，选择两个最重要的特征\n",
    "                if len(category_features) >= 2:\n",
    "                    top_category_features.extend(category_features.iloc[-2:]['特征'].tolist())\n",
    "                else:\n",
    "                    top_category_features.append(category_features.iloc[-1]['特征'])\n",
    "            elif category == 'crop':\n",
    "                top_category_features.append('Crop NUE')\n",
    "                pass\n",
    "            else:\n",
    "                # 添加该类别中最重要的特征\n",
    "                top_category_features.append(category_features.iloc[-1]['特征'])\n",
    "    \n",
    "    # 创建4个子图 - SHAP依赖图，排列在右侧\n",
    "    subplot_positions = [(0, 2), (0, 3), (1, 2), (1, 3)]\n",
    "    \n",
    "    for i, feature in enumerate(top_category_features):\n",
    "        if i >= len(subplot_positions):\n",
    "            break\n",
    "            \n",
    "        row, col = subplot_positions[i]\n",
    "        ax = plt.subplot2grid((2, 4), (row, col))\n",
    "        \n",
    "        # 获取该特征的索引\n",
    "        feature_idx = list(feature_names).index(feature)\n",
    "        \n",
    "        # 获取特征的颜色\n",
    "        color = feature_colors.get(feature, '#9E9E9E')\n",
    "        \n",
    "        # 绘制散点图\n",
    "        scatter = ax.scatter(features[feature], shap_values[:, feature_idx], \n",
    "                  alpha=0.5, s=20, \n",
    "                  c=color)\n",
    "        \n",
    "        # 排序数据以便绘制平滑线\n",
    "        idx = np.argsort(features[feature])\n",
    "        sorted_x = features[feature].iloc[idx]\n",
    "        sorted_y = shap_values[:, feature_idx][idx]\n",
    "        \n",
    "        # 使用LOWESS平滑\n",
    "        try:\n",
    "            if i == 3:\n",
    "                smoothed = lowess(sorted_y, sorted_x, frac=0.3)\n",
    "            else:\n",
    "                smoothed = lowess(sorted_y, sorted_x, frac=0.6)\n",
    "            # 绘制平滑线\n",
    "            ax.plot(smoothed[:, 0], smoothed[:, 1], color='gray', linewidth=2)\n",
    "        except:\n",
    "            # 如果LOWESS失败，尝试简单移动平均\n",
    "            window_size = max(5, len(sorted_y) // 20)  # 窗口大小\n",
    "            rolling_mean = pd.Series(sorted_y).rolling(window=window_size, center=True).mean()\n",
    "            ax.plot(sorted_x[rolling_mean.notna()], rolling_mean.dropna(), color='gray', linewidth=2)\n",
    "        \n",
    "        # 添加水平零线\n",
    "        ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "        \n",
    "        # 设置标签\n",
    "        ax.set_xlabel(feature, fontsize=16)\n",
    "        ax.set_ylabel('SHAP value', fontsize=16)\n",
    "        \n",
    "        # 设置轴范围\n",
    "        y_max = max(abs(shap_values[:, feature_idx].min()), abs(shap_values[:, feature_idx].max()))\n",
    "        ax.set_ylim(-y_max*1.1, y_max*1.1)\n",
    "        \n",
    "        # 设置网格和边框\n",
    "        ax.grid(True, linestyle='--', alpha=0.1)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    # 调整布局\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])  # 留出顶部空间放字母标签\n",
    "    \n",
    "    # 保存图像\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # 关闭图形\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"组合SHAP图已保存至 {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_drawing(X_df, best_model_patn, output_dir, period_name=None):\n",
    "    if isinstance(best_model_patn, str):\n",
    "        model = pickle.load(open(best_model_patn, 'rb'))\n",
    "    else:\n",
    "        model = best_model_patn\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_df)\n",
    "\n",
    "    # 创建输出目录\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 生成组合SHAP图\n",
    "    output_path = f'{output_dir}/{period_name}_combined_shap_plot.png'\n",
    "    create_combined_shap_plot(shap_values, X_df, output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df):\n",
    "    # 训练模型并评估\n",
    "    best_model = None\n",
    "    best_model_name = None\n",
    "    best_score = float('-inf')\n",
    "    try:\n",
    "        X, Y, x_tra, x_val, y_tra, y_val = countryDataset(df)\n",
    "    except:\n",
    "        raise Exception\n",
    "\n",
    "    x_tra_scaled, x_val_scaled = standardize_data(x_tra, x_val) \n",
    "    X_scaled = np.concatenate((x_tra_scaled, x_val_scaled), axis=0)\n",
    "    # 保存原始特征数据（未标准化的）\n",
    "    X_original = np.concatenate((x_tra, x_val), axis=0)\n",
    "\n",
    "    # 在模型评估中添加 tqdm 进度条\n",
    "    for name, model in tqdm.tqdm(models.items(), desc=f\"Training models\", ncols=100):\n",
    "        logging.info(f\"Training {name}...\")\n",
    "        train_r2, test_r2 = evaluate_model(model, x_tra_scaled, y_tra, x_val_scaled, y_val)\n",
    "\n",
    "        logging.info(f\"Model: {name}, Test R2: {test_r2:.4f}\")\n",
    "\n",
    "        if test_r2 > best_score:\n",
    "            best_model = model\n",
    "            best_score = test_r2\n",
    "            best_model_name = name\n",
    "\n",
    "    logging.info(f\"Best Model: {best_model_name} with Test R2: {best_score:.4f}\")\n",
    "    # 保存best_model\n",
    "    if best_model is not None:\n",
    "        if not os.path.exists(f'../{date}_model'):\n",
    "            os.makedirs(f'../{date}_model')\n",
    "        pickle.dump(best_model, open(f'../{date}_model/{best_model_name}.pkl', 'wb'))\n",
    "\n",
    "    # 使用最佳模型进行预测\n",
    "    # if best_model is not None:\n",
    "\n",
    "    #     y_pred = best_model.predict(X_scaled)\n",
    "\n",
    "        # 可视化预测结果\n",
    "        # global_plot_model_predictions(Y, y_pred, title=f\"{best_model_name} Ammonia Emission Prediction\")\n",
    "\n",
    "        # SHAP分析\n",
    "        # shap_analysis(best_model, pd.DataFrame(X_scaled, columns=X.columns), best_model_name)\n",
    "\n",
    "        # 确保所有日志输出已写入文件\n",
    "        logging.info(f\"Completed training and evaluation \\n\")\n",
    "    return best_model, best_model_name, best_score, X_scaled, X_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_output(X_df, best_model_patn, output_dir, X_original=None):\n",
    "    if isinstance(best_model_patn, str):\n",
    "        model = pickle.load(open(best_model_patn, 'rb'))\n",
    "    else:\n",
    "        model = best_model_patn\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_df)\n",
    "\n",
    "    # 创建输出目录\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 生成组合SHAP图 - 使用原始特征值而不是标准化后的值\n",
    "    output_path = f'{output_dir}/combined_shap_plot.png'\n",
    "    # 如果提供了原始数据，使用原始数据；否则使用标准化后的数据\n",
    "    features_for_plot = X_original if X_original is not None else X_df\n",
    "    create_combined_shap_plot(shap_values, features_for_plot, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_output(X_df, best_model_patn, output_dir, X_original=None):\n",
    "    if isinstance(best_model_patn, str):\n",
    "        model = pickle.load(open(best_model_patn, 'rb'))\n",
    "    else:\n",
    "        model = best_model_patn\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_df)\n",
    "\n",
    "    # 创建输出目录\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 生成组合SHAP图 - 使用原始特征值而不是标准化后的值\n",
    "    output_path = f'{output_dir}/combined_shap_plot.png'\n",
    "    # 如果提供了原始数据，使用原始数据；否则使用标准化后的数据\n",
    "    features_for_plot = X_original if X_original is not None else X_df\n",
    "    create_combined_shap_plot(shap_values, features_for_plot, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_output(X_df, best_model_patn, output_dir, X_original=None):\n",
    "    if isinstance(best_model_patn, str):\n",
    "        model = pickle.load(open(best_model_patn, 'rb'))\n",
    "    else:\n",
    "        model = best_model_patn\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_df)\n",
    "\n",
    "    # 创建输出目录\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 生成组合SHAP图 - 使用原始特征值而不是标准化后的值\n",
    "    output_path = f'{output_dir}/combined_shap_plot.png'\n",
    "    # 如果提供了原始数据，使用原始数据；否则使用标准化后的数据\n",
    "    features_for_plot = X_original if X_original is not None else X_df\n",
    "    create_combined_shap_plot(shap_values, features_for_plot, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models: 100%|████████████████████████████████████████████████| 6/6 [00:10<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "组合SHAP图已保存至 ../0624_shap_result/all/combined_shap_plot.png\n"
     ]
    }
   ],
   "source": [
    "df_tags = {\n",
    "    \"all\": df,\n",
    "    # \"before_1995\": df[df['year'] < 1995],\n",
    "    # \"before_2017\": df[df['year'] < 2017],\n",
    "    # \"after_2017\": df[df['year'] >= 2017]\n",
    "}\n",
    "\n",
    "for tag, df_tag in df_tags.items():\n",
    "    best_model, best_model_name, best_score, X_scaled, X_original = train_model(df_tag)\n",
    "    # 使用原始数据作为特征值显示，但SHAP值仍基于标准化数据计算\n",
    "    shap_output(pd.DataFrame(X_scaled, columns=df.columns[4:-1]), best_model, f\"../{date}_shap_result/{tag}\", \n",
    "                pd.DataFrame(X_original, columns=df.columns[4:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四象限shap组合图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Quadrant = pd.read_excel('../Data/副本国家氨排放强度原因解析612.xlsx')\n",
    "df_Quadrant = pd.concat([df, quadrant_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models: 100%|████████████████████████████████████████████████| 6/6 [00:11<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "组合SHAP图已保存至 ../0613_shap_result/第二象限/combined_shap_plot.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models: 100%|████████████████████████████████████████████████| 6/6 [00:10<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "组合SHAP图已保存至 ../0613_shap_result/第三象限/combined_shap_plot.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models: 100%|████████████████████████████████████████████████| 6/6 [00:08<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "组合SHAP图已保存至 ../0613_shap_result/第一象限/combined_shap_plot.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models: 100%|████████████████████████████████████████████████| 6/6 [00:09<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "组合SHAP图已保存至 ../0613_shap_result/第四象限/combined_shap_plot.png\n"
     ]
    }
   ],
   "source": [
    "Quadrants = df_Quadrant['区分象限'].unique()\n",
    "\n",
    "for quadrant in Quadrants:\n",
    "    if isinstance(quadrant, str):\n",
    "        df_quadrant = df_Quadrant[df_Quadrant['区分象限'] == quadrant]\n",
    "        df_quadrant = df_quadrant[df.columns]\n",
    "        best_model, best_model_name, best_score, X_scaled, X_original = train_model(df_quadrant)\n",
    "        # 使用原始数据作为特征值显示，但SHAP值仍基于标准化数据计算\n",
    "        shap_output(pd.DataFrame(X_scaled, columns=df.columns[4:-1]), best_model, f\"../{date}_shap_result/{quadrant}\", \n",
    "                    pd.DataFrame(X_original, columns=df.columns[4:-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dapsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
