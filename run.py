import numpy as np
import torch
import pickle
from problem import get
import logging
import sys
from pathlib import Path

from lhs import lhs
from pymoo.indicators.hv import HV
from pymoo.util.nds.non_dominated_sorting import NonDominatedSorting
from mobo.surrogate_model import GaussianProcess
from mobo.transformation import StandardTransform

from rf_optimization_problem import RandomForestMaximizationProblem
from catboost_optimization_problem import CatBoostMinimizationProblem
from spea2_env import environment_selection
from PM_mutation import pm_mutation
from GAN_model import GAN
from Generate import RMMEDA_operator
from pymop.factory import get_problem
from mating_selection import random_genetic_variation
from evolution.utils import *
from learning.model_init import *
from learning.model_update import *
from learning.prediction import *

# æ·»åŠ ç»˜å›¾å’Œä¿å­˜åŠŸèƒ½
import matplotlib.pyplot as plt
import pandas as pd
import os
from datetime import datetime
import json

# -----------------------------------------------------------------------------
# å®éªŒå‚æ•°è®¾ç½®
mmm = []
ins_list = [
              'zdt1','zdt2','zdt3','dtlz2','dtlz3','dtlz4','dtlz5','dtlz6','dtlz7','re1', 're2','re3','re4','re5','re6','re7'
            ]

# number of independent runs
n_run = 2
# number of initialized solutions
n_init = 100
# number of iterations, and batch size per iteration
n_iter = 20
n_sample = 5 

# PSL 
# number of learning steps
n_steps = 1000 
# number of sampled preferences per step
n_pref_update = 10 
# coefficient of LCB
coef_lcb = 0.1
# number of sampled candidates on the approxiamte Pareto front
n_candidate = 1000 
# number of optional local search
n_local = 1
# device
device = 'cuda'
# -----------------------------------------------------------------------------

# è®¾ç½®æ—¥å¿—å’Œç»“æœä¿å­˜
def setup_logging_and_directories():
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿå’Œåˆ›å»ºç»“æœç›®å½•"""
    
    # åˆ›å»ºç»“æœç›®å½•ç»“æ„
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    base_dir = Path("results") / f"experiment_{timestamp}"
    
    directories = {
        'base': base_dir,
        'logs': base_dir / "logs",
        'data': base_dir / "data", 
        'plots': base_dir / "plots",
        'pareto_fronts': base_dir / "pareto_fronts",
        'models': base_dir / "models",
        'populations': base_dir / "populations"
    }
    
    # åˆ›å»ºæ‰€æœ‰ç›®å½•
    for dir_path in directories.values():
        dir_path.mkdir(parents=True, exist_ok=True)
    
    # è®¾ç½®æ—¥å¿—é…ç½®
    log_file = directories['logs'] / "experiment.log"
    
    # åˆ›å»ºlogger
    logger = logging.getLogger('DAPSL_Experiment')
    logger.setLevel(logging.DEBUG)
    
    # æ¸…é™¤ç°æœ‰çš„å¤„ç†å™¨
    logger.handlers.clear()
    
    # æ–‡ä»¶å¤„ç†å™¨ - è¯¦ç»†æ—¥å¿—
    file_handler = logging.FileHandler(log_file, mode='w', encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)
    file_formatter = logging.Formatter(
        '%(asctime)s | %(levelname)-8s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    file_handler.setFormatter(file_formatter)
    logger.addHandler(file_handler)
    
    # æ§åˆ¶å°å¤„ç†å™¨ - ç®€åŒ–è¾“å‡º
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    console_formatter = logging.Formatter('%(levelname)s: %(message)s')
    console_handler.setFormatter(console_formatter)
    logger.addHandler(console_handler)
    
    return logger, directories

def save_population_data(X, Y, iteration, run_iter, problem_name, data_dir):
    """ä¿å­˜ç§ç¾¤æ•°æ®"""
    
    # ä¿å­˜å†³ç­–å˜é‡å’Œç›®æ ‡å€¼
    pop_data = {
        'decision_variables': X,
        'objective_values': Y,
        'iteration': iteration,
        'run': run_iter,
        'population_size': len(X),
        'problem': problem_name,
        'timestamp': datetime.now().isoformat()
    }
    
    filename = data_dir / f"population_{problem_name}_run{run_iter}_iter{iteration}.pkl"
    with open(filename, 'wb') as f:
        pickle.dump(pop_data, f)
    
    return filename

def save_pareto_front(Y, iteration, run_iter, problem_name, pareto_dir):
    """æå–å¹¶ä¿å­˜Paretoå‰æ²¿"""
    
    # ä½¿ç”¨éæ”¯é…æ’åºæå–Paretoå‰æ²¿
    nds = NonDominatedSorting()
    fronts = nds.do(Y)
    
    pareto_front_indices = fronts[0]
    pareto_front_Y = Y[pareto_front_indices]
    
    # ä¿å­˜Paretoå‰æ²¿æ•°æ®
    pareto_data = {
        'pareto_front_objectives': pareto_front_Y,
        'pareto_front_indices': pareto_front_indices,
        'iteration': iteration,
        'run': run_iter,
        'problem': problem_name,
        'front_size': len(pareto_front_Y),
        'timestamp': datetime.now().isoformat()
    }
    
    filename = pareto_dir / f"pareto_front_{problem_name}_run{run_iter}_iter{iteration}.pkl"
    with open(filename, 'wb') as f:
        pickle.dump(pareto_data, f)
    
    # åŒæ—¶ä¿å­˜ä¸ºCSVä¾¿äºæŸ¥çœ‹
    df = pd.DataFrame(pareto_front_Y, columns=[f'Obj_{i+1}' for i in range(pareto_front_Y.shape[1])])
    df['Run'] = run_iter
    df['Iteration'] = iteration
    csv_filename = pareto_dir / f"pareto_front_{problem_name}_run{run_iter}_iter{iteration}.csv"
    df.to_csv(csv_filename, index=False)
    
    return filename, pareto_front_Y

def save_convergence_metrics(hv_all_value, problem_name, data_dir):
    """ä¿å­˜æ”¶æ•›æŒ‡æ ‡"""
    
    metrics = {
        'hypervolume_matrix': hv_all_value,
        'mean_hv': np.mean(hv_all_value, axis=0),
        'std_hv': np.std(hv_all_value, axis=0),
        'best_hv': np.max(hv_all_value, axis=0),
        'worst_hv': np.min(hv_all_value, axis=0),
        'final_improvement': np.mean(hv_all_value[:, -1] - hv_all_value[:, 0]),
        'problem_name': problem_name,
        'n_runs': hv_all_value.shape[0],
        'n_iterations': hv_all_value.shape[1] - 1
    }
    
    filename = data_dir / f"convergence_metrics_{problem_name}.pkl"
    with open(filename, 'wb') as f:
        pickle.dump(metrics, f)
    
    return filename

def plot_convergence_with_save(hv_all_value, problem_name, plots_dir, logger):
    """ç»˜åˆ¶å¹¶ä¿å­˜æ”¶æ•›æ›²çº¿"""
    
    n_run, n_iter_plus1 = hv_all_value.shape
    n_iter = n_iter_plus1 - 1
    
    # è®¡ç®—ç»Ÿè®¡é‡
    mean_hv = np.mean(hv_all_value, axis=0)
    std_hv = np.std(hv_all_value, axis=0)
    
    # ç»˜åˆ¶æ”¶æ•›æ›²çº¿
    plt.figure(figsize=(12, 8))
    
    # ç»˜åˆ¶æ¯æ¬¡è¿è¡Œçš„æ›²çº¿
    for i in range(n_run):
        plt.plot(range(n_iter + 1), hv_all_value[i, :], 
                alpha=0.6, linewidth=1, label=f'Run {i+1}')
    
    # ç»˜åˆ¶å¹³å‡å€¼æ›²çº¿
    plt.plot(range(n_iter + 1), mean_hv, 
            'k-', linewidth=3, label='Mean')
    
    # ç»˜åˆ¶ç½®ä¿¡åŒºé—´
    plt.fill_between(range(n_iter + 1), 
                    mean_hv - std_hv, 
                    mean_hv + std_hv, 
                    alpha=0.2, color='black', label='Â±1 Std')
    
    plt.xlabel('Iteration', fontsize=12)
    plt.ylabel('Hypervolume', fontsize=12)
    plt.title(f'{problem_name} - Hypervolume Convergence', fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    # ä¿å­˜å›¾åƒ
    plot_filename = plots_dir / f"{problem_name}_convergence.png"
    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')
    plt.close()  # å…³é—­å›¾åƒä»¥é‡Šæ”¾å†…å­˜
    
    logger.info(f"æ”¶æ•›æ›²çº¿å·²ä¿å­˜: {plot_filename}")
    return plot_filename

# è®¾ç½®æ—¥å¿—å’Œç›®å½•
logger, directories = setup_logging_and_directories()

hv_list = {}

# åªæµ‹è¯•CatBoostæœ€å°åŒ–é—®é¢˜
ins_list = ['catboost_min']
dic = {
    'catboost_min': [0.2, 0.1],
    # 'rf_max': [-5.0, -5.0]  # æœ€å°åŒ–é—®é¢˜çš„å‚è€ƒç‚¹ (æ­£å€¼)
}

# è®°å½•å®éªŒå¼€å§‹
experiment_start_time = datetime.now()
logger.info("="*80)
logger.info(f"ğŸš€ DAPSL å®éªŒå¼€å§‹")
logger.info(f"å¼€å§‹æ—¶é—´: {experiment_start_time.strftime('%Y-%m-%d %H:%M:%S')}")
logger.info(f"ç»“æœä¿å­˜ç›®å½•: {directories['base']}")
logger.info("="*80)

# è®°å½•å®éªŒå‚æ•°
logger.info(f"å®éªŒå‚æ•°é…ç½®:")
logger.info(f"  - ç‹¬ç«‹è¿è¡Œæ¬¡æ•°: {n_run}")
logger.info(f"  - åˆå§‹è§£æ•°é‡: {n_init}")
logger.info(f"  - è¿­ä»£æ¬¡æ•°: {n_iter}")
logger.info(f"  - æ¯æ¬¡è¿­ä»£é‡‡æ ·æ•°: {n_sample}")
logger.info(f"  - LCBç³»æ•°: {coef_lcb}")
logger.info(f"  - å€™é€‰è§£æ•°é‡: {n_candidate}")
logger.info(f"  - è®¡ç®—è®¾å¤‡: {device}")

for test_ins in ins_list:
    logger.info("="*60)
    logger.info(f"ğŸ”¬ å¼€å§‹æµ‹è¯•é—®é¢˜: {test_ins}")
    logger.info("="*60)
    
    # get problem info
    hv_all_value = np.zeros([n_run, n_iter+1])
    
    # åˆ›å»ºCatBoostæœ€å°åŒ–é—®é¢˜
    if test_ins == 'catboost_min':
        problem = CatBoostMinimizationProblem(n_var=13, n_obj=2)
        n_dim = 13
        n_obj = 2
    else:
        problem = RandomForestMaximizationProblem(n_var=10, n_obj=2)
        n_dim = problem.n_var
        n_obj = problem.n_obj
    
    lbound = torch.zeros(n_dim).float()
    ubound = torch.ones(n_dim).float()
    ref_point = dic[test_ins]
    
    logger.info(f"é—®é¢˜ä¿¡æ¯:")
    logger.info(f"  - å˜é‡ç»´åº¦: {n_dim}")
    logger.info(f"  - ç›®æ ‡æ•°é‡: {n_obj}")
    logger.info(f"  - å˜é‡è¾¹ç•Œ: [0, 1]^{n_dim}")
    logger.info(f"  - å‚è€ƒç‚¹: {ref_point}")
    logger.info(f"  - è¿è¡Œæ¬¡æ•°: {n_run}")
    logger.info(f"  - è¿­ä»£æ¬¡æ•°: {n_iter}")
    
    # ä¸ºå½“å‰é—®é¢˜åˆ›å»ºä¸“é—¨çš„æ•°æ®ä¿å­˜ç›®å½•
    problem_data_dir = directories['data'] / test_ins
    problem_pareto_dir = directories['pareto_fronts'] / test_ins
    problem_pop_dir = directories['populations'] / test_ins
    
    for dir_path in [problem_data_dir, problem_pareto_dir, problem_pop_dir]:
        dir_path.mkdir(exist_ok=True)
    
    # repeatedly run the algorithm n_run times
    for run_iter in range(n_run):
        logger.info(f"\nğŸ”„ å¼€å§‹ç¬¬ {run_iter+1}/{n_run} æ¬¡è¿è¡Œ")
        
        i_iter = 1
        x_init = lhs(n_dim, n_init)
        y_init = problem.evaluate(x_init)
        
        # è®¡ç®—åˆå§‹HVå€¼
        hv = HV(ref_point=np.array(ref_point))
        initial_hv = hv(y_init)
        hv_all_value[run_iter, 0] = initial_hv
        logger.info(f"  ğŸ“ˆ åˆå§‹HVå€¼: {initial_hv:.4e}")
        
        # ä¿å­˜åˆå§‹ç§ç¾¤å’ŒParetoå‰æ²¿
        save_population_data(x_init, y_init, 0, run_iter, test_ins, problem_pop_dir)
        pf_file, pf_data = save_pareto_front(y_init, 0, run_iter, test_ins, problem_pareto_dir)
        logger.debug(f"  åˆå§‹Paretoå‰æ²¿å¤§å°: {len(pf_data)}")
        
        p_rel_map, s_rel_map = init_dom_rel_map(300)
        p_model = init_dom_nn_classifier(x_init, y_init, p_rel_map, pareto_dominance, problem)
        evaluated = len(y_init)

        X = x_init
        Y = y_init

        net = GAN(n_dim, 30, 0.0001, 200, n_dim)
        z = torch.zeros(n_obj).to(device)

        while evaluated < 200:
            logger.debug(f"    ğŸ” è¿­ä»£ {i_iter}, å·²è¯„ä¼°: {evaluated}")
            
            transformation = StandardTransform([0, 1])
            transformation.fit(X, Y)
            X_norm, Y_norm = transformation.do(X, Y)
            _, index = environment_selection(Y, len(X)//3)
            real = X[index, :]
            label = np.zeros((len(Y), 1))
            label[index, :] = 1
            net.train(X, label, real)
            surrogate_model = GaussianProcess(n_dim, n_obj, nu=5)
            surrogate_model.fit(X_norm, Y_norm)

            nds = NonDominatedSorting()
            idx_nds = nds.do(Y_norm)
            Y_nds = Y_norm[idx_nds[0]]

            X_gan = net.generate(real / np.tile(ubound, (np.shape(real)[0], 1)), n_init*10) * \
                          np.tile(ubound, (n_init*10, 1))
            X_gan = pm_mutation(X_gan, [lbound, ubound])
            X_ga = random_genetic_variation(real, 1000,list(np.zeros(n_dim)),list(np.ones(n_dim)),n_dim)
            X_gan = np.concatenate((X_ga, X_gan), axis=0)

            p_dom_labels, p_cfs = nn_predict_dom_inter(X_gan, real, p_model, device)
            
            res = np.sum(p_dom_labels,axis=1)
            iindex = np.argpartition(-res, 100)
            result_args = iindex[:100]
            X_dp = X_gan[result_args,:]

            X_psl = RMMEDA_operator(np.concatenate((X_dp, real), axis=0), 5, n_obj, lbound, ubound)

            Y_candidate_mean = surrogate_model.evaluate(X_psl)['F']
            Y_candidata_std = surrogate_model.evaluate(X_psl, std=True)['S']
            Y_candidate = Y_candidate_mean - coef_lcb * Y_candidata_std
            Y_candidate_mean = Y_candidate
            
            best_subset_list = []
            Y_p = Y_nds
            for b in range(n_sample):
                hv = HV(ref_point=np.max(np.vstack([Y_p, Y_candidate_mean]), axis=0))
                best_hv_value = 0
                best_subset = None

                for k in range(len(Y_candidate_mean)):
                    Y_subset = Y_candidate_mean[k]
                    Y_comb = np.vstack([Y_p, Y_subset])
                    hv_value_subset = hv(Y_comb)
                    if hv_value_subset > best_hv_value:
                        best_hv_value = hv_value_subset
                        best_subset = [k]

                Y_p = np.vstack([Y_p, Y_candidate_mean[best_subset]])
                best_subset_list.append(best_subset)
            best_subset_list = np.array(best_subset_list).T[0]

            X_candidate = X_psl
            X_new = X_candidate[best_subset_list]

            Y_new = problem.evaluate(X_new)
            Y_new = torch.tensor(Y_new).to(device)

            X_new = torch.tensor(X_new).to(device)
            X = np.vstack([X, X_new.detach().cpu().numpy()])
            Y = np.vstack([Y, Y_new.detach().cpu().numpy()])

            update_dom_nn_classifier(p_model, X, Y, p_rel_map, pareto_dominance, problem)

            hv = HV(ref_point=np.array(ref_point))
            hv_value = hv(Y)
            hv_all_value[run_iter, i_iter] = hv_value
            
            # è®¡ç®—HVå˜åŒ–
            hv_change = hv_value - hv_all_value[run_iter, i_iter-1] if i_iter > 0 else 0
            logger.debug(f"      ğŸ“Š HVå€¼: {hv_value:.4e} (å˜åŒ–: {hv_change:+.4e})")
            
            # ä¿å­˜å½“å‰è¿­ä»£çš„ç§ç¾¤å’ŒParetoå‰æ²¿
            save_population_data(X, Y, i_iter, run_iter, test_ins, problem_pop_dir)
            pf_file, pf_data = save_pareto_front(Y, i_iter, run_iter, test_ins, problem_pareto_dir)
            logger.debug(f"      å½“å‰Paretoå‰æ²¿å¤§å°: {len(pf_data)}")
            
            i_iter = i_iter+1
            evaluated = evaluated + n_sample

        final_hv = hv_all_value[run_iter, -1]
        improvement = final_hv - hv_all_value[run_iter, 0]
        logger.info(f"  âœ… ç¬¬ {run_iter+1} æ¬¡è¿è¡Œå®Œæˆ")
        logger.info(f"    æœ€ç»ˆHVå€¼: {final_hv:.4e}")
        logger.info(f"    HVæ”¹è¿›: {improvement:+.4e}")
        logger.info(f"    æœ€ç»ˆç§ç¾¤å¤§å°: {len(Y)}")

    # ä¿å­˜ç»“æœåˆ°hv_list
    hv_list[test_ins] = hv_all_value
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    mean_hv = np.mean(hv_all_value, axis=0)
    std_hv = np.std(hv_all_value, axis=0)
    best_hv = np.max(hv_all_value, axis=0)
    
    logger.info(f"\nğŸ“ˆ {test_ins} é—®é¢˜ç»“æœç»Ÿè®¡:")
    logger.info(f"  - æœ€ç»ˆå¹³å‡HV: {mean_hv[-1]:.4e} Â± {std_hv[-1]:.4e}")
    logger.info(f"  - æœ€ç»ˆæœ€ä½³HV: {best_hv[-1]:.4e}")
    logger.info(f"  - å¹³å‡HVæ”¹è¿›: {mean_hv[-1] - mean_hv[0]:.4e}")
    logger.info(f"  - æ”¹è¿›ç™¾åˆ†æ¯”: {((mean_hv[-1] - mean_hv[0])/mean_hv[0]*100):.2f}%")
    
    # ä¿å­˜æ”¶æ•›æŒ‡æ ‡
    metrics_file = save_convergence_metrics(hv_all_value, test_ins, problem_data_dir)
    logger.info(f"  ğŸ“Š æ”¶æ•›æŒ‡æ ‡å·²ä¿å­˜: {metrics_file}")
    
    # ä¿å­˜è¯¦ç»†ç»“æœåˆ°CSV
    results_df = pd.DataFrame(hv_all_value.T, 
                            columns=[f'Run_{i+1}' for i in range(n_run)])
    results_df['Iteration'] = range(n_iter + 1)
    results_df['Mean_HV'] = mean_hv
    results_df['Std_HV'] = std_hv
    results_df['Best_HV'] = best_hv
    
    csv_filename = problem_data_dir / f"{test_ins}_hv_results.csv"
    results_df.to_csv(csv_filename, index=False)
    logger.info(f"  ğŸ’¾ è¯¦ç»†HVç»“æœå·²ä¿å­˜: {csv_filename}")
    
    # ç»˜åˆ¶å¹¶ä¿å­˜æ”¶æ•›æ›²çº¿
    plot_file = plot_convergence_with_save(hv_all_value, test_ins, directories['plots'], logger)
    
    logger.info("="*60)

# ä¿å­˜å®Œæ•´çš„å®éªŒç»“æœ
pickle_filename = directories['data'] / "hv_list_complete.pkl"
with open(pickle_filename, 'wb') as f:
    pickle.dump(hv_list, f)

# ä¿å­˜å®éªŒæ€»ç»“
experiment_end_time = datetime.now()
experiment_duration = experiment_end_time - experiment_start_time

summary = {
    'experiment_info': {
        'start_time': experiment_start_time.strftime('%Y-%m-%d %H:%M:%S'),
        'end_time': experiment_end_time.strftime('%Y-%m-%d %H:%M:%S'),
        'duration_seconds': experiment_duration.total_seconds(),
        'duration_str': str(experiment_duration),
        'base_directory': str(directories['base'])
    },
    'parameters': {
        'n_runs': n_run,
        'n_init': n_init,
        'n_iterations': n_iter,
        'n_samples_per_iter': n_sample,
        'coef_lcb': coef_lcb,
        'n_candidate': n_candidate,
        'device': device
    },
    'problems_tested': list(ins_list),
    'results_summary': {}
}

for problem_name, hv_data in hv_list.items():
    mean_hv = np.mean(hv_data, axis=0)
    std_hv = np.std(hv_data, axis=0)
    summary['results_summary'][problem_name] = {
        'initial_hv_mean': float(mean_hv[0]),
        'initial_hv_std': float(std_hv[0]),
        'final_hv_mean': float(mean_hv[-1]),
        'final_hv_std': float(std_hv[-1]),
        'improvement_mean': float(mean_hv[-1] - mean_hv[0]),
        'improvement_percentage': float((mean_hv[-1] - mean_hv[0])/mean_hv[0]*100),
        'best_hv': float(np.max(hv_data)),
        'worst_hv': float(np.min(hv_data[:, -1])),
        'convergence_stability': float(std_hv[-1]/mean_hv[-1])  # å˜å¼‚ç³»æ•°
    }

summary_filename = directories['data'] / "experiment_summary.json"
with open(summary_filename, 'w', encoding='utf-8') as f:
    json.dump(summary, f, indent=2, ensure_ascii=False)

# ä¿å­˜æ–‡ä»¶æ¸…å•
file_manifest = {
    'directories': {k: str(v) for k, v in directories.items()},
    'key_files': {
        'experiment_log': str(directories['logs'] / "experiment.log"),
        'complete_results': str(pickle_filename),
        'experiment_summary': str(summary_filename),
        'convergence_plots': str(directories['plots']),
        'pareto_fronts': str(directories['pareto_fronts']),
        'population_data': str(directories['populations'])
    },
    'file_counts': {
        'pareto_front_files': len(list(directories['pareto_fronts'].rglob("*.pkl"))),
        'population_files': len(list(directories['populations'].rglob("*.pkl"))),
        'plot_files': len(list(directories['plots'].rglob("*.png")))
    }
}

manifest_filename = directories['base'] / "file_manifest.json"
with open(manifest_filename, 'w', encoding='utf-8') as f:
    json.dump(file_manifest, f, indent=2, ensure_ascii=False)

logger.info("="*80)
logger.info("ğŸ å®éªŒå®Œæˆ!")
logger.info(f"  â±ï¸  æ€»è€—æ—¶: {experiment_duration}")
logger.info(f"  ğŸ“ ç»“æœä¿å­˜ç›®å½•: {directories['base']}")
logger.info(f"  ğŸ“‹ å®éªŒæ€»ç»“: {summary_filename}")
logger.info(f"  ğŸ’¾ å®Œæ•´ç»“æœ: {pickle_filename}")
logger.info(f"  ğŸ“Š æ–‡ä»¶æ¸…å•: {manifest_filename}")
logger.info(f"  ğŸ“ˆ æ—¥å¿—æ–‡ä»¶: {directories['logs'] / 'experiment.log'}")

# è¾“å‡ºæ–‡ä»¶ç»“æ„æ€»ç»“
logger.info(f"\nğŸ“‚ ç”Ÿæˆçš„æ–‡ä»¶ç»“æ„:")
logger.info(f"  ğŸ“ {directories['base']}/")
logger.info(f"    ğŸ“ data/ - å®éªŒæ•°æ®å’ŒæŒ‡æ ‡")
logger.info(f"    ğŸ“ logs/ - è¯¦ç»†æ—¥å¿—æ–‡ä»¶")
logger.info(f"    ğŸ“ plots/ - æ”¶æ•›æ›²çº¿å›¾")
logger.info(f"    ğŸ“ pareto_fronts/ - Paretoå‰æ²¿æ•°æ®")
logger.info(f"    ğŸ“ populations/ - ç§ç¾¤æ¼”åŒ–æ•°æ®")
logger.info(f"    ğŸ“ models/ - è®­ç»ƒçš„æ¨¡å‹(å¦‚æœ‰)")

logger.info("="*80)

# æœ€ç»ˆçš„ç®€è¦ç»Ÿè®¡è¾“å‡ºåˆ°æ§åˆ¶å°
print(f"\nğŸ‰ å®éªŒæˆåŠŸå®Œæˆ!")
print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {directories['base']}")
print(f"â±ï¸  è€—æ—¶: {experiment_duration}")
for problem_name, summary_data in summary['results_summary'].items():
    print(f"ğŸ“Š {problem_name}: HVæ”¹è¿› {summary_data['improvement_percentage']:.2f}%")

# æˆ–è€…äº¤äº’å¼ä½¿ç”¨
from hv_list_complete import DAPSLResultAnalyzer
analyzer = DAPSLResultAnalyzer()
analyzer.select_experiment(0)  # é€‰æ‹©æœ€æ–°å®éªŒ
analyzer.generate_comprehensive_report("catboost_min")





